using NAudio.Wave;
using System;
using System.Collections.Generic;
using System.Threading;
using VADdotnet;

namespace VadDotNet;

public class SimpleRealTimeVad : IDisposable
{
    private readonly SileroVadOnnxModel _model;
    private readonly WaveInEvent _waveIn;
    private readonly WaveOutEvent _waveOut;
    private readonly EchoCancellationWaveProvider _echoCancellationProvider;
    private readonly BufferedWaveProvider _bufferedWaveProvider;
    private readonly int _sampleRate;
    private readonly int _windowSize;
    private readonly float _threshold;
    
    private readonly Queue<float> _audioBuffer;
    private readonly object _bufferLock = new object();
    private bool _isRecording = false;
    private bool _isDisposed = false;
    
    // èªéŸ³æª¢æ¸¬äº‹ä»¶
    public event EventHandler<SpeechDetectedEventArgs> SpeechDetected;
    public event EventHandler<SpeechEndedEventArgs> SpeechEnded;
    public event EventHandler<VoiceActivityEventArgs> VoiceActivityChanged;
    
    // çµ±è¨ˆä¿¡æ¯
    public int TotalFramesProcessed { get; private set; }
    public int SpeechFramesDetected { get; private set; }
    public double SpeechActivityRatio => TotalFramesProcessed > 0 ? (double)SpeechFramesDetected / TotalFramesProcessed : 0;
    
    public SimpleRealTimeVad(string onnxModelPath, float threshold = 0.5f, int sampleRate = 16000)
    {
        _sampleRate = sampleRate;
        _threshold = threshold;
        _windowSize = sampleRate == 16000 ? 512 : 256;
        
        // ç›´æ¥åˆå§‹åŒ– ONNX æ¨¡å‹
        _model = new SileroVadOnnxModel(onnxModelPath);
        
        // åˆå§‹åŒ–éŸ³é »ç·©è¡å€
        _audioBuffer = new Queue<float>();
        
        // åˆå§‹åŒ– WaveIn
        _waveIn = new WaveInEvent
        {
            WaveFormat = new WaveFormat(sampleRate, 16, 1),
            BufferMilliseconds = 20
        };
        
        _waveIn.DataAvailable += OnDataAvailable;

        _waveOut = new WaveOutEvent
        {
            DesiredLatency = 100 // è¨­ç½®ç·©è¡å€å»¶é²
        };

        _bufferedWaveProvider = new BufferedWaveProvider(_waveIn.WaveFormat)
        {
            ReadFully = true // ç¢ºä¿å¯ä»¥å®Œæ•´è®€å–ç·©è¡å€
        };

        _echoCancellationProvider = new EchoCancellationWaveProvider(20, 200, _bufferedWaveProvider);
        _waveOut.Init(_echoCancellationProvider);
    }
    
    public void Play()
    {
        if (_isDisposed) throw new ObjectDisposedException(nameof(SimpleRealTimeVad));
        if (!_isRecording) throw new InvalidOperationException("è«‹å…ˆé–‹å§‹éŒ„éŸ³æ‰èƒ½æ’­æ”¾éŸ³é »ã€‚");
        
        _waveOut.Play();
        Console.WriteLine("ğŸ”Š é–‹å§‹æ’­æ”¾å¯¦æ™‚éŸ³é »...");
    }

    public void Stop()
    {
        if (_isDisposed) throw new ObjectDisposedException(nameof(SimpleRealTimeVad));
        if (!_isRecording) throw new InvalidOperationException("è«‹å…ˆé–‹å§‹éŒ„éŸ³æ‰èƒ½æš«åœæ’­æ”¾ã€‚");
        
        _waveOut.Stop();
        Console.WriteLine("â¸ï¸ æš«åœå¯¦æ™‚éŸ³é »æ’­æ”¾...");
    }

    public void StartRecording()
    {
        if (_isDisposed) throw new ObjectDisposedException(nameof(SimpleRealTimeVad));
        if (_isRecording) return;
        
        _isRecording = true;
        _waveIn.StartRecording();
        Console.WriteLine($"ğŸ¤ é–‹å§‹å¯¦æ™‚èªéŸ³æª¢æ¸¬ (æ¡æ¨£ç‡: {_sampleRate}Hz, é–¾å€¼: {_threshold:F2})");
    }
    
    public void StopRecording()
    {
        if (!_isRecording) return;
        
        _isRecording = false;
        _waveIn.StopRecording();
        Console.WriteLine("â¹ï¸ åœæ­¢å¯¦æ™‚èªéŸ³æª¢æ¸¬");
    }
    
    private void OnDataAvailable(object sender, WaveInEventArgs e)
    {
        if (!_isRecording) return;
        
        try
        {
            // å°‡å­—ç¯€æ•¸æ“šè½‰æ›ç‚ºæµ®é»æ•¸
            var samples = ConvertBytesToFloats(e.Buffer, e.BytesRecorded);
            
            lock (_bufferLock)
            {
                // å°‡æ¨£æœ¬æ·»åŠ åˆ°ç·©è¡å€
                foreach (var sample in samples)
                {
                    _audioBuffer.Enqueue(sample);
                }
                
                // è™•ç†å®Œæ•´çš„çª—å£
                ProcessAudioWindows();
            }
        }
        catch (Exception ex)
        {
            Console.WriteLine($"âŒ è™•ç†éŸ³é »æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {ex.Message}");
        }
    }
    
    private void ProcessAudioWindows()
    {
        while (_audioBuffer.Count >= _windowSize)
        {
            // æå–ä¸€å€‹çª—å£çš„æ¨£æœ¬
            var window = new float[_windowSize];
            for (int i = 0; i < _windowSize; i++)
            {
                window[i] = _audioBuffer.Dequeue();
            }
            
            // ä½¿ç”¨ VAD æª¢æ¸¬èªéŸ³
            ProcessAudioWindow(window);
        }
    }
    
    private void ProcessAudioWindow(float[] window)
    {
        TotalFramesProcessed++;
        
        try
        {
            // æª¢æ¸¬èªéŸ³æ´»å‹•
            float speechProbability = _model.Call(new[] { window }, _sampleRate)[0];
            
            bool isSpeech = speechProbability >= _threshold;
            
            if (isSpeech)
            {
                SpeechFramesDetected++;

                var output = ConvertFloatsToBytes(window);
                var cancelledOutput = new byte[output.Length];
                _echoCancellationProvider.Cancel(output, cancelledOutput);
                _bufferedWaveProvider.AddSamples(cancelledOutput, 0, cancelledOutput.Length);
            }


            // è§¸ç™¼èªéŸ³æ´»å‹•äº‹ä»¶
            VoiceActivityChanged?.Invoke(this, new VoiceActivityEventArgs
            {
                SpeechProbability = speechProbability,
                IsSpeech = isSpeech,
                Timestamp = DateTime.Now,
                FrameIndex = TotalFramesProcessed
            });
            
            // æª¢æ¸¬èªéŸ³é–‹å§‹å’ŒçµæŸ
            DetectSpeechSegments(speechProbability);
            
            // é¡¯ç¤ºå¯¦æ™‚ç‹€æ…‹
            DisplayRealTimeStatus(speechProbability, isSpeech);
        }
        catch (Exception ex)
        {
            Console.WriteLine($"âŒ VAD è™•ç†éŒ¯èª¤: {ex.Message}");
        }
    }
    
    private bool _lastSpeechState = false;
    private DateTime _speechStartTime = DateTime.MinValue;
    
    private void DetectSpeechSegments(float speechProbability)
    {
        bool currentSpeechState = speechProbability >= _threshold;
        
        // æª¢æ¸¬èªéŸ³é–‹å§‹
        if (currentSpeechState && !_lastSpeechState)
        {
            _speechStartTime = DateTime.Now;
            SpeechDetected?.Invoke(this, new SpeechDetectedEventArgs
            {
                StartTime = _speechStartTime,
                SpeechProbability = speechProbability
            });
        }
        
        // æª¢æ¸¬èªéŸ³çµæŸ
        if (!currentSpeechState && _lastSpeechState)
        {
            var speechDuration = DateTime.Now - _speechStartTime;
            SpeechEnded?.Invoke(this, new SpeechEndedEventArgs
            {
                StartTime = _speechStartTime,
                EndTime = DateTime.Now,
                Duration = speechDuration,
                AverageProbability = speechProbability
            });
        }
        
        _lastSpeechState = currentSpeechState;
    }
    
    private void DisplayRealTimeStatus(float speechProbability, bool isSpeech)
    {
        // æ¯ 50 å¹€æ›´æ–°ä¸€æ¬¡é¡¯ç¤ºï¼ˆç´„æ¯ç§’ 2-3 æ¬¡ï¼‰
        if (TotalFramesProcessed % 50 == 0)
        {
            Console.Clear();
            Console.WriteLine("ğŸ¤ å¯¦æ™‚èªéŸ³æª¢æ¸¬ç‹€æ…‹");
            Console.WriteLine("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
            Console.WriteLine($"ğŸ“Š èªéŸ³æ¦‚ç‡: {speechProbability:F3}");
            Console.WriteLine($"ğŸ¯ ç•¶å‰ç‹€æ…‹: {(isSpeech ? "ğŸ”Š èªéŸ³" : "ğŸ”‡ éœéŸ³")}");
            Console.WriteLine($"ğŸ“ˆ èªéŸ³æ´»å‹•ç‡: {SpeechActivityRatio:P1}");
            Console.WriteLine($"ğŸ“Š ç¸½å¹€æ•¸: {TotalFramesProcessed:N0}");
            Console.WriteLine($"ğŸ¤ èªéŸ³å¹€æ•¸: {SpeechFramesDetected:N0}");
            Console.WriteLine($"â±ï¸  é‹è¡Œæ™‚é–“: {GetRunningTime()}");
            Console.WriteLine();
            Console.WriteLine("æŒ‰ Ctrl+C åœæ­¢æª¢æ¸¬...");
        }
    }
    
    private string GetRunningTime()
    {
        // å‡è¨­æ¯å¹€ 20ms
        var totalSeconds = TotalFramesProcessed * 0.02;
        var minutes = (int)(totalSeconds / 60);
        var seconds = (int)(totalSeconds % 60);
        return $"{minutes:D2}:{seconds:D2}";
    }
    
    private float[] ConvertBytesToFloats(byte[] buffer, int bytesRecorded)
    {
        var samples = new float[bytesRecorded / 2];
        for (int i = 0; i < samples.Length; i++)
        {
            short sample = BitConverter.ToInt16(buffer, i * 2);
            samples[i] = sample / 32768f; // æ­£è¦åŒ–åˆ° [-1, 1]
        }
        return samples;
    }

    private byte[] ConvertFloatsToBytes(float[] samples)
    {
        var buffer = new byte[samples.Length * 2];
        for (int i = 0; i < samples.Length; i++)
        {
            short sample = (short)(samples[i] * 32768); // å°‡æµ®é»æ•¸è½‰æ›ç‚ºçŸ­æ•´å‹
            BitConverter.GetBytes(sample).CopyTo(buffer, i * 2);
        }
        return buffer;
    }

    public void Dispose()
    {
        if (_isDisposed) return;
        
        StopRecording();
        _waveIn?.Dispose();
        _model?.Dispose();
        _isDisposed = true;
    }
} 